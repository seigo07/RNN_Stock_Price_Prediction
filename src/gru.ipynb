{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yfinance as yf\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "SEED_VALUE = 42\n",
    "np.random.seed(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)\n",
    "\n",
    "ticker = \"AAPL\"\n",
    "end = datetime.now()\n",
    "start = datetime(2016, end.month, end.day)\n",
    "dataset = yf.download(ticker, start, end)\n",
    "\n",
    "# Data Cleaning\n",
    "# Handle Missing Data\n",
    "dataset = dataset.dropna()  # Remove rows with missing data\n",
    "\n",
    "# Remove Duplicates\n",
    "dataset = dataset[~dataset.index.duplicated(keep='first')]\n",
    "\n",
    "# Handle Outliers (Clipping values)\n",
    "lower_bound = 0  # Define lower bound for clipping\n",
    "upper_bound = np.percentile(dataset['Close'], 99)  # Define upper bound for clipping (99th percentile)\n",
    "dataset['Close'] = np.clip(dataset['Close'], lower_bound, upper_bound)\n",
    "\n",
    "# Preprocess the data\n",
    "data = dataset['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "\n",
    "# Function to create sequences for GRU models\n",
    "def create_dataset(dataset, time_steps=1):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(dataset) - time_steps):\n",
    "        a = dataset[i:(i + time_steps), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(dataset[i + time_steps, 0])\n",
    "    return np.array(data_X), np.array(data_Y)\n",
    "\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 20\n",
    "\n",
    "# Create sequences for GRU models\n",
    "X_train, y_train = create_dataset(train_data, sequence_length)\n",
    "X_test, y_test = create_dataset(test_data, sequence_length)\n",
    "\n",
    "\n",
    "# Build the GRU model\n",
    "def build_gru_model(lr):\n",
    "    gru_model = Sequential()\n",
    "    gru_model.add(GRU(50, activation='relu', input_shape=(sequence_length, 1)))\n",
    "    gru_model.add(Dense(1))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    gru_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return gru_model\n",
    "\n",
    "\n",
    "# Define hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'epochs': [10, 20, 30],\n",
    "    'batch_size': [16, 32, 64]\n",
    "}\n",
    "\n",
    "best_params = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "# Grid search for best hyperparameters\n",
    "for params in ParameterGrid(param_grid):\n",
    "    gru_model = build_gru_model(lr=params['learning_rate'])\n",
    "    gru_model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], verbose=0)\n",
    "    gru_predictions = gru_model.predict(X_test)\n",
    "    gru_predictions = scaler.inverse_transform(gru_predictions)\n",
    "    gru_rmse = np.sqrt(mean_squared_error(data[train_size + sequence_length:], gru_predictions))\n",
    "\n",
    "    if gru_rmse < best_rmse:\n",
    "        best_rmse = gru_rmse\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Build and train the GRU model with best hyperparameters\n",
    "gru_model = build_gru_model(lr=best_params['learning_rate'])\n",
    "gru_model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "\n",
    "# Delete this part\n",
    "# chosen_learning_rate = 0.001\n",
    "# chosen_epochs = 20\n",
    "# chosen_batch_size = 32\n",
    "# gru_model = build_gru_model(lr=chosen_learning_rate)\n",
    "# gru_model.fit(X_train, y_train, epochs=chosen_epochs, batch_size=chosen_batch_size, verbose=1)\n",
    "\n",
    "# Generate predictions for the GRU model\n",
    "gru_predictions = gru_model.predict(X_test)\n",
    "gru_predictions = scaler.inverse_transform(gru_predictions)\n",
    "\n",
    "\n",
    "# Function to calculate Theil U statistic\n",
    "def theil_u_statistic(actual, predicted, naive):\n",
    "    mse_actual = mean_squared_error(actual, naive)\n",
    "    mse_predicted = mean_squared_error(actual, predicted)\n",
    "    theil_u = np.sqrt(mse_predicted / mse_actual)\n",
    "    return theil_u\n",
    "\n",
    "\n",
    "# Generate naive predictions (using the last value in the training set)\n",
    "naive_predictions = np.full_like(y_test, y_train[-1])\n",
    "\n",
    "# Calculate indexes\n",
    "gru_rmse = np.sqrt(mean_squared_error(data[train_size + sequence_length:], gru_predictions))\n",
    "gru_mae = mean_absolute_error(data[train_size + sequence_length:], gru_predictions)\n",
    "gru_r2 = r2_score(data[train_size + sequence_length:], gru_predictions)\n",
    "gru_mape = mean_absolute_percentage_error(data[train_size + sequence_length:], gru_predictions)\n",
    "gru_theil_u = theil_u_statistic(data[train_size + sequence_length:], gru_predictions, naive_predictions)\n",
    "\n",
    "print(f\"RMSE: {gru_rmse}\")\n",
    "print(f\"MAE: {gru_mae}\")\n",
    "print(f\"R2: {gru_r2}\")\n",
    "print(f\"MAPE: {gru_mape:.2f}%\")\n",
    "print(f\"Theil U statistic : {gru_theil_u:.2f}\")\n",
    "\n",
    "gru_predictions_list = gru_predictions.flatten().tolist()\n",
    "\n",
    "# Get data for the last one year\n",
    "one_year_ago = datetime.now() - timedelta(days=365)\n",
    "one_year_data = dataset[dataset.index >= one_year_ago]\n",
    "\n",
    "# Rescale the one-year data for plotting\n",
    "one_year_data_2d = one_year_data['Close'].values.reshape(-1, 1)\n",
    "one_year_data_scaled = scaler.transform(one_year_data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Create sequences for GRU models for the one-year data\n",
    "X_one_year, y_one_year = create_dataset(one_year_data_scaled, sequence_length)\n",
    "\n",
    "# Generate predictions for the GRU model on the one-year data\n",
    "gru_predictions_one_year = gru_model.predict(X_one_year)\n",
    "gru_predictions_one_year = scaler.inverse_transform(gru_predictions_one_year)\n",
    "\n",
    "# Initialize variables for the trading strategy for the one-year period\n",
    "initial_balance = 1000  # Initial balance (USD)\n",
    "balance = initial_balance\n",
    "stocks = 0\n",
    "N = len(gru_predictions_one_year)  # Use the one-year price direction data\n",
    "\n",
    "# Implement the trading strategy for the one-year period\n",
    "for i in range(N):\n",
    "    if gru_predictions_one_year[i] > one_year_data_2d[i]:  # Predicted price will rise\n",
    "        stocks_to_buy = int(balance / one_year_data['Close'][i + sequence_length])\n",
    "        stocks += stocks_to_buy\n",
    "        balance -= stocks_to_buy * one_year_data['Close'][i + sequence_length]\n",
    "    else:  # Predicted price will fall\n",
    "        balance += stocks * one_year_data['Close'][i + sequence_length]\n",
    "        stocks = 0\n",
    "\n",
    "# Calculate profit or loss at the end of the one-year period\n",
    "final_balance = balance + stocks * one_year_data['Close'][-1]\n",
    "profit_or_loss = final_balance - initial_balance\n",
    "\n",
    "print(f\"Initial Balance: ${initial_balance}\")\n",
    "print(f\"Final Balance: ${final_balance:.2f}\")\n",
    "print(f\"Profit or Loss: ${profit_or_loss:.2f}\")\n",
    "\n",
    "# Plot the predictions with buy/sell points for the one-year period\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(one_year_data.index[sequence_length:], one_year_data['Close'][sequence_length:], label='Actual Stock Price')\n",
    "plt.plot(one_year_data.index[sequence_length:], gru_predictions_one_year, label='GRU Predicted Stock Price')\n",
    "plt.scatter(one_year_data.index[sequence_length:], gru_predictions_one_year, marker='o', color='g',\n",
    "            label='Buy' if gru_predictions_one_year[-1] > one_year_data_2d[-1] else 'Sell')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price (USD)')\n",
    "plt.title(f'{ticker} Stock Price Predictions with Buy/Sell Points (Last One Year)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Format x-axis ticks to show one month intervals\n",
    "plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add more descriptive labels to the X and Y axes\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price (USD)')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-01T22:53:00.523191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T18:02:19.613206Z",
     "start_time": "2023-07-23T18:02:19.596508Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
