{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-03T14:39:46.760600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from itertools import product\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yfinance as yf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Initialize GPU config\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "    except RuntimeError:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        pass\n",
    "\n",
    "SEED_VALUE = 42\n",
    "np.random.seed(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)\n",
    "\n",
    "ticker = \"AAPL\"\n",
    "end = datetime.now()\n",
    "start = datetime(2016, end.month, end.day)\n",
    "dataset = yf.download(ticker, start, end)\n",
    "\n",
    "# Data Cleaning\n",
    "# Handle Missing Data\n",
    "dataset = dataset.dropna()  # Remove rows with missing data\n",
    "\n",
    "# Remove Duplicates\n",
    "dataset = dataset[~dataset.index.duplicated(keep='first')]\n",
    "\n",
    "# Handle Outliers (Clipping values)\n",
    "lower_bound = 0  # Define lower bound for clipping\n",
    "upper_bound = np.percentile(dataset['Close'], 99)  # Define upper bound for clipping (99th percentile)\n",
    "dataset['Close'] = np.clip(dataset['Close'], lower_bound, upper_bound)\n",
    "\n",
    "# Preprocess the data\n",
    "data = dataset['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# Reshape train_data and test_data to 2D arrays\n",
    "train_data_2d = train_data.reshape(-1, 1)\n",
    "test_data_2d = test_data.reshape(-1, 1)\n",
    "\n",
    "# Function to calculate Theil U statistic\n",
    "def theil_u_statistic(actual, predicted, naive):\n",
    "    mse_actual = mean_squared_error(actual, naive)\n",
    "    mse_predicted = mean_squared_error(actual, predicted)\n",
    "    theil_u = np.sqrt(mse_predicted / mse_actual)\n",
    "    return theil_u\n",
    "\n",
    "# Grid search for best ARIMA hyperparameters\n",
    "param_grid = {\n",
    "    'p': range(0, 3),  # Narrow the range for p\n",
    "    'd': range(1, 3),\n",
    "    'q': range(0, 2)  # Narrow the range for q\n",
    "}\n",
    "\n",
    "# Function to perform time series cross-validation\n",
    "def time_series_cross_validation(data, n_splits, model_order):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    theil_u_scores = []\n",
    "    for train_index, test_index in tscv.split(data):\n",
    "        train_data = data[train_index]\n",
    "        test_data = data[test_index]\n",
    "\n",
    "        # Preprocess the data\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        train_data = scaler.fit_transform(train_data)\n",
    "        test_data = scaler.transform(test_data)\n",
    "\n",
    "        # Reshape train_data and test_data to 2D arrays\n",
    "        train_data_2d = train_data.reshape(-1, 1)\n",
    "        test_data_2d = test_data.reshape(-1, 1)\n",
    "\n",
    "        history = [x for x in train_data_2d]\n",
    "        predictions = []\n",
    "        for t in range(len(test_data_2d)):\n",
    "            model = ARIMA(history, order=model_order)\n",
    "            model_fit = model.fit()\n",
    "            output = model_fit.forecast(steps=1)\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            obs = test_data_2d[t]\n",
    "            history.append(obs)\n",
    "\n",
    "        # Calculate Theil U\n",
    "        arima_naive_predictions = np.full_like(test_data_2d, train_data_2d[-1])\n",
    "        arima_theil_u = theil_u_statistic(test_data_2d, predictions, arima_naive_predictions)\n",
    "        theil_u_scores.append(arima_theil_u)\n",
    "\n",
    "    return np.mean(theil_u_scores)\n",
    "\n",
    "# Perform grid search with time series cross-validation\n",
    "best_theil_u = float('inf')\n",
    "best_arima_predictions = None\n",
    "for p, d, q in product(param_grid['p'], param_grid['d'], param_grid['q']):\n",
    "    model_order = (p, d, q)\n",
    "    theil_u_score = time_series_cross_validation(data, n_splits=5, model_order=model_order)\n",
    "\n",
    "    # Update best hyperparameters if Theil U improves\n",
    "    if theil_u_score < best_theil_u:\n",
    "        best_theil_u = theil_u_score\n",
    "        best_p, best_d, best_q = p, d, q\n",
    "\n",
    "# Train the final model using the best hyperparameters\n",
    "history = [x for x in train_data_2d]\n",
    "best_arima_predictions = []\n",
    "for t in range(len(test_data_2d)):\n",
    "    model = ARIMA(history, order=(best_p, best_d, best_q))\n",
    "    model_fit = model.fit()\n",
    "    output = model_fit.forecast(steps=1)\n",
    "    yhat = output[0]\n",
    "    best_arima_predictions.append(yhat)\n",
    "    obs = test_data_2d[t]\n",
    "    history.append(obs)\n",
    "\n",
    "# # Generate predictions for the ARIMA model\n",
    "arima_predictions = best_arima_predictions\n",
    "arima_predictions = np.array(arima_predictions).flatten()\n",
    "arima_predictions = scaler.inverse_transform(arima_predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Generate naive predictions (using the last value in the training set)\n",
    "naive_predictions = np.full_like(test_data, train_data[-1])\n",
    "\n",
    "# Calculate RMSE\n",
    "arima_rmse = np.sqrt(mean_squared_error(data[train_size:], arima_predictions))\n",
    "arima_mae = mean_absolute_error(data[train_size:], arima_predictions)\n",
    "arima_r2 = r2_score(data[train_size:], arima_predictions)\n",
    "arima_mape = mean_absolute_percentage_error(data[train_size:], arima_predictions)\n",
    "\n",
    "print(f\"Best ARIMA Parameters: p={best_p}, d={best_d}, q={best_q}\")\n",
    "print(f\"RMSE: {arima_rmse}\")\n",
    "print(f\"MAE: {arima_mae}\")\n",
    "print(f\"R2: {arima_r2}\")\n",
    "print(f\"MAPE: {arima_mape:.2f}%\")\n",
    "print(f\"Theil U statistic : {best_theil_u:.2f}\")\n",
    "\n",
    "# Get data for the last one year\n",
    "one_year_ago = datetime.now() - timedelta(days=365)\n",
    "one_year_data = dataset[dataset.index >= one_year_ago]\n",
    "\n",
    "# Rescale the one-year data for plotting\n",
    "one_year_data_scaled = scaler.transform(one_year_data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Reshape one_year_data_scaled to 2D array\n",
    "one_year_data_2d = one_year_data_scaled.reshape(-1, 1)\n",
    "one_year_2d = one_year_data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# Reshape history to include one_year_data\n",
    "history = train_data_2d.tolist() + one_year_data_2d.tolist()\n",
    "\n",
    "# Predict using ARIMA model for the one-year period\n",
    "one_year_arima_predictions = []\n",
    "for t in range(len(one_year_data_2d)):\n",
    "    model = ARIMA(history, order=(1, 2, 0))\n",
    "    model_fit = model.fit()\n",
    "    output = model_fit.forecast(steps=1)\n",
    "    yhat = output[0]\n",
    "    one_year_arima_predictions.append(yhat)\n",
    "    obs = one_year_data_2d[t]\n",
    "    history.append(obs)\n",
    "\n",
    "# Convert one_year_arima_predictions list to a 1D numpy array\n",
    "one_year_arima_predictions = np.array(one_year_arima_predictions).flatten()\n",
    "one_year_arima_predictions = scaler.inverse_transform(one_year_arima_predictions.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Initialize variables for the trading strategy for the one-year period\n",
    "initial_balance = 1000  # Initial balance (USD)\n",
    "balance = initial_balance\n",
    "stocks = 0\n",
    "N = len(one_year_arima_predictions)  # Use the one-year price direction data\n",
    "\n",
    "# Implement the trading strategy for the one-year period\n",
    "for i in range(N):\n",
    "    if one_year_arima_predictions[i] > one_year_2d[i]:  # Predicted price will rise\n",
    "        stocks_to_buy = int(balance / one_year_data['Close'].iloc[i])\n",
    "        stocks += stocks_to_buy\n",
    "        balance -= stocks_to_buy * one_year_data['Close'].iloc[i]\n",
    "    else:  # Predicted price will fall\n",
    "        balance += stocks * one_year_data['Close'].iloc[i]\n",
    "        stocks = 0\n",
    "\n",
    "# Calculate profit or loss at the end of the one-year period\n",
    "final_balance = balance + stocks * one_year_data['Close'].iloc[-1]\n",
    "profit_or_loss = final_balance - initial_balance\n",
    "\n",
    "print(f\"Initial Balance: ${initial_balance}\")\n",
    "print(f\"Final Balance: ${final_balance:.2f}\")\n",
    "print(f\"Profit or Loss: ${profit_or_loss:.2f}\")\n",
    "\n",
    "# Plot the predictions with buy/sell points for the one-year period\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(one_year_data.index, one_year_data['Close'].values, label='Actual Stock Price')\n",
    "plt.plot(one_year_data.index, one_year_arima_predictions, label='ARIMA Predicted Stock Price')\n",
    "plt.scatter(one_year_data.index, one_year_arima_predictions, marker='o', color='g',\n",
    "            label='Buy' if one_year_arima_predictions[-1] > one_year_2d[-1] else 'Sell')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price (USD)')\n",
    "plt.title(f'{ticker} Stock Price Predictions with Buy/Sell Points (Last One Year)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Format x-axis ticks to show one month intervals\n",
    "plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add more descriptive labels to the X and Y axes\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price (USD)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
